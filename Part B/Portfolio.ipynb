{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "24/7/24 Started finding a suitable kaggle dataset to use for the assessment.\n",
    "\n",
    "24/7/24 Found a dataset on the top 1000 IMDB movies (see imdb_top_1000.csv).\n",
    "\n",
    "24/7/24 Started the Identifying and Defining worksheet.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying and Defining\n",
    "\n",
    "Learning Intentions:\n",
    "Specify the functional requirements of a data analysis, including stating the purpose of a solution, describing use cases, and developing test cases of inputs and expected outputs.\n",
    "Specify the non-functional requirements of a data analysis.\n",
    "Success Criteria:\n",
    "\n",
    "- I can clearly state the purpose of a data analysis solution.\n",
    "\n",
    "- I can describe use cases that outline how the data analysis solution will be used.\n",
    "\n",
    "- I can develop test cases that include inputs and expected outputs for the data analysis solution.\n",
    "\n",
    "- I can specify non-functional requirements such as performance, scalability, security, and usability for a data analysis solution.\n",
    "\n",
    "- I can explain the importance of non-functional requirements in ensuring the overall quality and effectiveness of a data analysis solution.\n",
    "\n",
    "## Identifying and Defining\n",
    "\n",
    "- Data: I am looking to analyze the top 1000 IMDb rated movies.\n",
    "- Goal: My goal is to find what movies are highly rated and other characteristices of it (e.g. production date and genre)\n",
    "- Source: The source of the dataset is from \"Harshit Shankhdhar\", a user on Kaggle who made the .csv file.\n",
    "- Access: This file is publicly available on kaggle, you can find it at https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows.\n",
    "- Access Method: It will be accessed as a .csv file.\n",
    "\n",
    "## Functional Requirements\n",
    "\n",
    "The functions you need to consider for this task are:\n",
    "- Data Loading: All files must be able to open and work, not being corrupted or broken of any sort. This is to ensure that all the work can be correctly viewed and graded.\n",
    "- Data Cleaning: The program needs to be able to handle any missing values while also being able to filter, sort and group specific data in the file, such as by production date, name, etc.\n",
    "- Data Analysis: It also needs to be able to analyze the data by finding the mean, median, mode and quartiles.\n",
    "- Data Visualisation: The data will be visualised in pandas dataframes, as well as being shown in different types of matplotlib graphs.\n",
    "- Data Reporting: The final input of the data sorting will be put into a new csv file in the same folder as the code. For example, if the user wants to sort the IMDb dataset with only 9+ ratings, then the file will be called \"imdb_top_1000_updated.csv\".\n",
    "\n",
    "- Function Name (e.g. Data Loading)\n",
    "    - Description: It must be able to efficiently analyse the dataset and sort the data to whatever the user of the program says, like movies from a specific year.\n",
    "    - Input: The program will ask what the user wants to sort the data from.\n",
    "    - Output: The person's input will be put into the code and sorted, which then is output onto a graph or a table for it to work. There will also be a .csv file to show the result as well.\n",
    "\n",
    "## Use Cases\n",
    "Use cases essentially describe how users will interact with the system by providing an example of how it will work. The following example demonstrates how you create a use-case and the template should be used to create a use-case for each functional requirement.\n",
    "Actor: User\n",
    "Goal: To load a dataset into the system.\n",
    "Preconditions: User has a dataset file ready.\n",
    "Main Flow:\n",
    "1. User places the dataset for reading into the correct folder.\n",
    "2. System validates the file format.\n",
    "3. System loads the dataset and displays the information in a dataframe.\n",
    "Postconditions: Dataset is loaded and ready for analysis.\n",
    "\n",
    "## Non-Functional Requirements\n",
    "Typically non-functional requirements would focus on performance, usability, reliability, scalability and security. However, for this task we are going to focus on usability and reliability, as the performance and scalability will not vary much due to only working with one or two datasets and security was a bit much to cram into the short time we have to complete the task. You are of course welcome to add a security layer (e.g. username + password) to your UI if you feel it's appropriate, and if you have time.\n",
    "\n",
    "For now, focus on the following:\n",
    "\n",
    "- Usability: What is required from the User Interface and a 'README' document?\n",
    "\n",
    "- Reliability: What is required from the system when providing information to the user on errors and ensuring data integrity?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
