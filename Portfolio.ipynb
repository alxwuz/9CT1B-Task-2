{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "24/7/24 Started finding a suitable kaggle dataset to use for the assessment.\n",
    "\n",
    "24/7/24 Found a dataset on the top 1000 IMDB movies (see imdb_top_1000.csv).\n",
    "\n",
    "24/7/24 Started the Identifying and Defining worksheet.\n",
    "\n",
    "31/7/24 Finished the Identifying and Defiing worksheet and started the Researching and Planning worksheet.\n",
    "\n",
    "15/8/24 Done the Research and Planning worksheet, starting the Producting and Implementing stage.\n",
    "\n",
    "15/8/24 Added the welcome input, program will ask what category they would want to sort, adding more later."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying and Defining\n",
    "- Data: I am looking to analyze the top 1000 IMDb rated movies.\n",
    "- Goal: My goal is to find what movies are highly rated and other characteristices of it (e.g. production date and genre)\n",
    "- Source: The source of the dataset is from \"Harshit Shankhdhar\", a user on Kaggle who made the .csv file.\n",
    "- Access: This file is publicly available on kaggle, you can find it at https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows.\n",
    "- Access Method: It will be accessed as a .csv file.\n",
    "\n",
    "## Functional Requirements\n",
    "- Data Loading: All files must be able to open and work, not being corrupted or broken of any sort. This is to ensure that all the work can be correctly viewed and graded.\n",
    "- Data Cleaning: The program needs to be able to handle any missing values while also being able to filter, sort and group specific data in the file, such as by production date, name, etc.\n",
    "- Data Analysis: It also needs to be able to analyze the data by finding the mean, median, mode and quartiles.\n",
    "- Data Visualisation: The data will be visualised in pandas dataframes, as well as being shown in different types of matplotlib graphs.\n",
    "- Data Reporting: The final input of the data sorting will be put into a new csv file in the same folder as the code. For example, if the user wants to sort the IMDb dataset with only 9+ ratings, then the file will be called \"imdb_top_1000_updated.csv\".\n",
    "\n",
    "- The Code\n",
    "    - Description: It must be able to efficiently analyse the dataset and sort the data to whatever the user of the program says, like movies from a specific year.\n",
    "    - Input: The program will ask what the user wants to sort the data from.\n",
    "    - Output: The person's input will be put into the code and sorted, which then is output onto a graph or a table for it to work. There will also be a .csv file to show the result as well.\n",
    "\n",
    "## Use Cases\n",
    "Actor: User\n",
    "Goal: To find the highest rated movie in the dataset.\n",
    "Preconditions: User can run the written code.\n",
    "Main Flow:\n",
    "1. User uses the UI to navigate the code.\n",
    "2. System asks what the user wants.\n",
    "3. User says the highest rated movie.\n",
    "4. System identifies and gives it.\n",
    "Postconditions: The movie has been found.\n",
    "\n",
    "## Non-Functional Requirements\n",
    "- Usability: The user interface needs to have an easy-to-use UI, where you can know what you want to sort out efficiently. The \"README\" document will need to have instructions on what to do and how to use the sorting system.\n",
    "- Reliability: If there is ever an error (e.g. not finding the right movie), there will be suggestions on how to fix it, like not entering the right spelling of the category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research and Planning\n",
    "## Research of Chosen Issue\n",
    "- Purpose: I am trying to find out the top 1000 IMDb movies based on their rating. The dataset also includes some other information, such as the movie description and the total gross. Although there is a lot of info on these movies, the dataset is missing some movies from the current years, which makes it important to do further research so that it is up to date.\n",
    "\n",
    "- Missing Data: There is a total of 4 years worth of movie data (2020-2024) that are missing, which is a very important period of time. This means that lots of movies are not in the dataset, meaning people cannot find recent movies, and therefore making some people not want to use the program.\n",
    "\n",
    "- Stakeholders: People who will benefit include people who want to find a good movie to watch.\n",
    "\n",
    "- Use: Users of this data analysis will be able to search for something they want to watch, based on how to use the program, ranging from finding the right genre to how well IMDb rated the movie.\n",
    "\n",
    "## Privacy and Security\n",
    "- Data Privacy of Source: The data from the .csv file is completely public, the user who made it just put all the data from the IDMb website into an easy-access .csv file. There is not much need for privacy of the source, as the dataset is found on Kaggle, which is a public site where people can find datasets and more. If you register to this site, it's TOS says that your profile can be public and others can see it, so the source agreed and has the responsibilities. For the participants, they can use the dataset if they have an account, thus making them agree to the TOS. Although they have this TOS, they still need to protect the user's personal info (such as their birthdate, name, age and gender).\n",
    "\n",
    "- Application Data Privacy: The responsibilities of the program include that all of the sensetive info that is stored will not be looked or collected, the program must use a password with extra optional features (2FA, email verification) to ensure the data cannot be leaked. It should also follow all of the data privacy laws, like the right to be forgotten (all data gathered from the user is deleted).\n",
    "\n",
    "- Cyber Security: Once it is available, there should be many features like user authentication, which is a process where you verify that someone who tries to access the account is the real owner (this could be done by things like 2FA, etc.). Another security feature is password hashing, where your password is encrypted into a short string of letters and numbers to prevent hackers reaching your password. This can also be used for other things like the sensitive data stored in servers, and more.\n",
    "\n",
    "## Data Dictionaries\n",
    "| Field | Datatype | Format for Display | Description | Example | Validation |\n",
    "| ----- | -------- | ------------------ | ----------- | ------- | ---------- |\n",
    "| Series_Title | object | XX...XX | The title of the movie | The Matrix | Can only include letters and numbers|\n",
    "| Released_Year | object | NNNN | The year the movie was released | 1999 | Can only include numbers |\n",
    "| Certificate | object | XX...XX | The age rating of the movie | A | Can include anything |\n",
    "| Runtime | object | XX.X min | How long the movie lasts for | 136 min | Must only include letters and numbers|\n",
    "| Genre | object | \"XX...XX\" | The genre of the movie | \"Action, Sci-Fi\" | Can include anything |\n",
    "| IMDB_Rating | float64 | N.N | The rating of the movie | 8.7 | Must be a number with optional decimals |\n",
    "| Overview | object | \"XX...XX\" | The description of the movie | When a beautiful stranger leads computer hacker...| Can be anything |\n",
    "| Meta_score | int | NNN | The weighted average of all ratings of the movie | 74 | Ranging from 2-3 numbers |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and Evaluating\n",
    "## Analyse and Conclude\n",
    "- Data Visualisation: In my data analysis program, there were a lot of both charts that were provided and generated, which you can find in my code. You can find a histogram of the frequency of all IMDb ratings spread out, along with a bunch of charts/tables that provide more information about the data set (e.g. most and least popular movies).\n",
    "- Calculations: The calculations from the code I have made normally ask for the user's input, and then from the input, they see if it is in the dataset. If it is, then it prints the dataset along with the move title (sort by released year). This is very similar to sorting by genre, but sorting by genre is harder as you have to convert the data into the right type and make the invalid ones show \"NaN\", just as well as stripping the commas and going through the data to find the correct genre. With this type of code, it will be very accurate because of how it can handle errors and successfully print the dataset with the right info.\n",
    "- Accuracy: The information is accurate because it uses a very dataset which you can find in 'data/imdb_top_1000.csv'. It uses correct info from the official source (IMDb) and puts it into an easy to use and read dataset (except for stripping the spaces and commas).\n",
    "- Conclusions: In conclusion, this dataset is mainly about the top 1000 highest rated IMDb movies (as of 2020), along with a lot of other details like the gross income and director of the movie. This can be uses [along with my program :)] to find good movies that people can watch, find and analyse.\n",
    "\n",
    "## Peer Evaluation\n",
    "### Sebastian Tam\n",
    " For functional requirements, I believe that Alex has successfully completed all of these in his code. In data loading, all of the files work and are able to be opened. For data cleaning, Alex drops that data that he doesnâ€™t need anymore. Alex has options for analysis, by showing the results from the dataset. For data visualisation, Alex has matplotlib charts so that we can see the results in a chart. There is data reporting, as you can see in the csv file. For non-functional requirements, Alex completes both of these. The UI is easy to use, and shows the error if something goes wrong.\n",
    "\n",
    "### Kelvin Guo\n",
    "Alex's code is fully functional and meets all functional requirements, the graph is easy to read and Alex's code can automatically give you relevant information. On the other hand, Alex does meets most of the non-functionial standards, like a very easy to use UI, but he does not have more complicated ones like a username or password or a GUI. Overall, Alex's code is simple and easy to use and is reliable.\n",
    "\n",
    "## Evaluation of Final Product in Relation to Functional and Non-Functional Requirements\n",
    "Throughout the end of last term and the start of this term, I have been making a program in which it sorts a selected dataset (in this case I have chosen the top 1000 IMDb rated movies), and give info about it, such as the genre of the movies, the stars in it, and many more. The functional requirements that were needed in this task were all correctly implemented and working. This means the program can sort the dataset from the piece of code, use matplotlib to make a graph, find the mean, and have a working UI without any errors.\n",
    "\n",
    "As for the non-functional requirements, there have been some that was put into the code, like listing all the possible options (for example the genres in the dataset), making the updated tables much more readable and coherent, and more. Although with these types of non-functional requirements, there are still some more features that should be added to have more quality-of-life improvements. These improvements include things such as a GUI and a user login. Overall, there are some good non-functional requirements, but there could be more added.\n",
    "\n",
    "## Evaluation of your Project in Relation to Testing and Project Management\n",
    "During this assessment task, there have been lots of ups and downs in terms of time management, debugging and solving, challenges and effort. For the positive aspects, I have done a lot of problem solving for the errors that were hapenning in my code, and I have fixed them and made them work easily, resulting in a high-quality program which can sort the chosen dataset very efficiently and easily. While programming, there have been some challenges I have faced while doing it, and the most notable one is probably when I couldn't even run my code (on my laptop nor the computer) because it would say \"Module not found\", even though the requirements were already satisfied. I fixed this by adding a .venv file to the repository (thank you so much VSCode), which basically makes a seperate environment where I can install the modules and run the program without disturbing the global files. Although I have done these things, I did not plan my work well and had to do lots of work in the last few weeks of the assessment task. Nonetheless, I believe I have put a lot of blood and tears into this assessment task, along with learning some new things about python. Therefore, although this was a landslide, I have still managed to overcome the problems and make everything work."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
